{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow\nfrom tensorflow.keras.layers import Layer,Dense,Embedding,Lambda,Multiply,Input,Flatten,Concatenate\nfrom tensorflow.keras.models import Model\nimport numpy as np\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.utils import plot_model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-03T11:18:08.609462Z","iopub.execute_input":"2023-12-03T11:18:08.609868Z","iopub.status.idle":"2023-12-03T11:18:08.615829Z","shell.execute_reply.started":"2023-12-03T11:18:08.609833Z","shell.execute_reply":"2023-12-03T11:18:08.614820Z"},"trusted":true},"execution_count":200,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n# Load the Boston Housing Prices dataset\nboston = load_diabetes()\nX, y = boston.data, boston.target\n\n# Standardize the data\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T11:18:08.621436Z","iopub.execute_input":"2023-12-03T11:18:08.621792Z","iopub.status.idle":"2023-12-03T11:18:08.635088Z","shell.execute_reply.started":"2023-12-03T11:18:08.621753Z","shell.execute_reply":"2023-12-03T11:18:08.634160Z"},"trusted":true},"execution_count":201,"outputs":[]},{"cell_type":"markdown","source":"# Layer And Model","metadata":{}},{"cell_type":"code","source":"class SuperDense(Layer):\n    \n    def __init__(self, *args, **kwargs):\n        super(SuperDense, self).__init__()\n        \n        self.dense2 = Dense(128, activation=\"softmax\")\n        self.lamb = Lambda(self.softLambda)\n        self.embed = Embedding(input_dim=128, output_dim=32)\n        self.var = [i for i in range(128)]\n        self.my_variable = self.add_weight(\n            name=\"my_variable\",\n            shape=(1,),\n            initializer=\"zeros\",\n            trainable=True,\n        )\n\n    def softLambda(self, x):\n        return K.cast(K.greater_equal(x, 0.5), K.floatx())\n\n    def call(self, inputs):\n        x = self.dense2(inputs)\n        x = self.lamb(x)\n        \n        # Ensure x has the shape [batch_size, 128]\n        x = Multiply()([K.constant(self.var,shape=(1, 128)), x])\n        x = self.embed(x)\n        x = Flatten()(x)        \n        return x\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T11:18:08.640183Z","iopub.execute_input":"2023-12-03T11:18:08.640478Z","iopub.status.idle":"2023-12-03T11:18:08.649173Z","shell.execute_reply.started":"2023-12-03T11:18:08.640454Z","shell.execute_reply":"2023-12-03T11:18:08.648168Z"},"trusted":true},"execution_count":202,"outputs":[]},{"cell_type":"code","source":"ip=Input((X_scaled.shape[1],))\ny=Dense(124,activation=\"relu\")(ip)\nz=Dense(128,activation=\"relu\")(y)\ny=SuperDense()(y)\ncnc=Concatenate()([z,y])\ndense2=Dense(12,activation=\"relu\")(cnc)\nop=Dense(1,activation=\"relu\")(dense2)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T11:18:08.660852Z","iopub.execute_input":"2023-12-03T11:18:08.661518Z","iopub.status.idle":"2023-12-03T11:18:08.739431Z","shell.execute_reply.started":"2023-12-03T11:18:08.661493Z","shell.execute_reply":"2023-12-03T11:18:08.738613Z"},"trusted":true},"execution_count":203,"outputs":[]},{"cell_type":"code","source":"model=Model([ip],[op])","metadata":{"execution":{"iopub.status.busy":"2023-12-03T11:18:08.740944Z","iopub.execute_input":"2023-12-03T11:18:08.741291Z","iopub.status.idle":"2023-12-03T11:18:08.749376Z","shell.execute_reply.started":"2023-12-03T11:18:08.741246Z","shell.execute_reply":"2023-12-03T11:18:08.748614Z"},"trusted":true},"execution_count":204,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=\"adam\",loss=\"mae\")","metadata":{"execution":{"iopub.status.busy":"2023-12-03T11:18:08.750956Z","iopub.execute_input":"2023-12-03T11:18:08.751329Z","iopub.status.idle":"2023-12-03T11:18:08.764386Z","shell.execute_reply.started":"2023-12-03T11:18:08.751295Z","shell.execute_reply":"2023-12-03T11:18:08.763607Z"},"trusted":true},"execution_count":205,"outputs":[]},{"cell_type":"code","source":"ip2=Input((X_scaled.shape[1],))\ny2=Dense(124,activation=\"relu\")(ip2)\nz2=Dense(128,activation=\"relu\")(y2)\ny2=Dense(128,activation=\"relu\")(y2)\ncnc2=Concatenate()([z2,y2])\ndense22=Dense(256,activation=\"relu\")(cnc2)\nop2=Dense(1,activation=\"relu\")(dense22)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T11:18:08.766220Z","iopub.execute_input":"2023-12-03T11:18:08.766521Z","iopub.status.idle":"2023-12-03T11:18:08.827172Z","shell.execute_reply.started":"2023-12-03T11:18:08.766496Z","shell.execute_reply":"2023-12-03T11:18:08.826276Z"},"trusted":true},"execution_count":206,"outputs":[]},{"cell_type":"code","source":"model2=Model([ip2],[op2])","metadata":{"execution":{"iopub.status.busy":"2023-12-03T11:18:08.828301Z","iopub.execute_input":"2023-12-03T11:18:08.828659Z","iopub.status.idle":"2023-12-03T11:18:08.837186Z","shell.execute_reply.started":"2023-12-03T11:18:08.828624Z","shell.execute_reply":"2023-12-03T11:18:08.836198Z"},"trusted":true},"execution_count":207,"outputs":[]},{"cell_type":"code","source":"model2.compile(optimizer=\"adam\",loss=\"mae\")","metadata":{"execution":{"iopub.status.busy":"2023-12-03T11:18:08.838571Z","iopub.execute_input":"2023-12-03T11:18:08.838858Z","iopub.status.idle":"2023-12-03T11:18:08.850932Z","shell.execute_reply.started":"2023-12-03T11:18:08.838833Z","shell.execute_reply":"2023-12-03T11:18:08.849954Z"},"trusted":true},"execution_count":208,"outputs":[]},{"cell_type":"markdown","source":"# **Regression Test**","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\nmodel.fit(X_train,y_train, epochs=200,validation_split=0.3)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T11:18:53.592798Z","iopub.execute_input":"2023-12-03T11:18:53.593159Z","iopub.status.idle":"2023-12-03T11:19:06.330091Z","shell.execute_reply.started":"2023-12-03T11:18:53.593130Z","shell.execute_reply":"2023-12-03T11:19:06.329111Z"},"trusted":true},"execution_count":213,"outputs":[{"name":"stdout","text":"Epoch 1/200\n8/8 [==============================] - 0s 13ms/step - loss: 29.4908 - val_loss: 47.9161\nEpoch 2/200\n8/8 [==============================] - 0s 8ms/step - loss: 29.6434 - val_loss: 47.1264\nEpoch 3/200\n8/8 [==============================] - 0s 8ms/step - loss: 29.3068 - val_loss: 48.0511\nEpoch 4/200\n8/8 [==============================] - 0s 8ms/step - loss: 29.1175 - val_loss: 47.1197\nEpoch 5/200\n8/8 [==============================] - 0s 8ms/step - loss: 29.2195 - val_loss: 47.9124\nEpoch 6/200\n8/8 [==============================] - 0s 8ms/step - loss: 28.9475 - val_loss: 47.1534\nEpoch 7/200\n8/8 [==============================] - 0s 8ms/step - loss: 28.8967 - val_loss: 48.0047\nEpoch 8/200\n8/8 [==============================] - 0s 8ms/step - loss: 28.8998 - val_loss: 47.3630\nEpoch 9/200\n8/8 [==============================] - 0s 8ms/step - loss: 28.8974 - val_loss: 48.0731\nEpoch 10/200\n8/8 [==============================] - 0s 8ms/step - loss: 28.7510 - val_loss: 47.4543\nEpoch 11/200\n8/8 [==============================] - 0s 8ms/step - loss: 28.7511 - val_loss: 47.9410\nEpoch 12/200\n8/8 [==============================] - 0s 8ms/step - loss: 28.8271 - val_loss: 47.7388\nEpoch 13/200\n8/8 [==============================] - 0s 8ms/step - loss: 28.5086 - val_loss: 47.7734\nEpoch 14/200\n8/8 [==============================] - 0s 8ms/step - loss: 28.2891 - val_loss: 48.0875\nEpoch 15/200\n8/8 [==============================] - 0s 8ms/step - loss: 28.3920 - val_loss: 47.6037\nEpoch 16/200\n8/8 [==============================] - 0s 8ms/step - loss: 28.3709 - val_loss: 48.1051\nEpoch 17/200\n8/8 [==============================] - 0s 8ms/step - loss: 28.1887 - val_loss: 47.4584\nEpoch 18/200\n8/8 [==============================] - 0s 8ms/step - loss: 28.3210 - val_loss: 47.7903\nEpoch 19/200\n8/8 [==============================] - 0s 8ms/step - loss: 27.9923 - val_loss: 47.6276\nEpoch 20/200\n8/8 [==============================] - 0s 8ms/step - loss: 27.9824 - val_loss: 47.9247\nEpoch 21/200\n8/8 [==============================] - 0s 8ms/step - loss: 27.8397 - val_loss: 48.2036\nEpoch 22/200\n8/8 [==============================] - 0s 8ms/step - loss: 27.8048 - val_loss: 47.9632\nEpoch 23/200\n8/8 [==============================] - 0s 8ms/step - loss: 27.6720 - val_loss: 47.9071\nEpoch 24/200\n8/8 [==============================] - 0s 8ms/step - loss: 27.5822 - val_loss: 48.5181\nEpoch 25/200\n8/8 [==============================] - 0s 8ms/step - loss: 27.6029 - val_loss: 48.7588\nEpoch 26/200\n8/8 [==============================] - 0s 7ms/step - loss: 27.4624 - val_loss: 47.7896\nEpoch 27/200\n8/8 [==============================] - 0s 7ms/step - loss: 27.1926 - val_loss: 49.1315\nEpoch 28/200\n8/8 [==============================] - 0s 8ms/step - loss: 27.4329 - val_loss: 47.9556\nEpoch 29/200\n8/8 [==============================] - 0s 8ms/step - loss: 27.4710 - val_loss: 48.5887\nEpoch 30/200\n8/8 [==============================] - 0s 8ms/step - loss: 27.1292 - val_loss: 48.1154\nEpoch 31/200\n8/8 [==============================] - 0s 9ms/step - loss: 27.4381 - val_loss: 48.2173\nEpoch 32/200\n8/8 [==============================] - 0s 8ms/step - loss: 27.2978 - val_loss: 49.2183\nEpoch 33/200\n8/8 [==============================] - 0s 8ms/step - loss: 27.1234 - val_loss: 48.3513\nEpoch 34/200\n8/8 [==============================] - 0s 8ms/step - loss: 26.7044 - val_loss: 48.8130\nEpoch 35/200\n8/8 [==============================] - 0s 8ms/step - loss: 26.6018 - val_loss: 48.4449\nEpoch 36/200\n8/8 [==============================] - 0s 8ms/step - loss: 26.4810 - val_loss: 48.9848\nEpoch 37/200\n8/8 [==============================] - 0s 7ms/step - loss: 26.4556 - val_loss: 48.5183\nEpoch 38/200\n8/8 [==============================] - 0s 8ms/step - loss: 26.8424 - val_loss: 48.7619\nEpoch 39/200\n8/8 [==============================] - 0s 7ms/step - loss: 26.1260 - val_loss: 48.8520\nEpoch 40/200\n8/8 [==============================] - 0s 8ms/step - loss: 26.2996 - val_loss: 49.4388\nEpoch 41/200\n8/8 [==============================] - 0s 8ms/step - loss: 26.1214 - val_loss: 48.5460\nEpoch 42/200\n8/8 [==============================] - 0s 7ms/step - loss: 26.2720 - val_loss: 48.9087\nEpoch 43/200\n8/8 [==============================] - 0s 8ms/step - loss: 26.1079 - val_loss: 49.1377\nEpoch 44/200\n8/8 [==============================] - 0s 8ms/step - loss: 25.9325 - val_loss: 49.1033\nEpoch 45/200\n8/8 [==============================] - 0s 8ms/step - loss: 25.7885 - val_loss: 50.3868\nEpoch 46/200\n8/8 [==============================] - 0s 8ms/step - loss: 25.8245 - val_loss: 48.5552\nEpoch 47/200\n8/8 [==============================] - 0s 8ms/step - loss: 25.4298 - val_loss: 49.9957\nEpoch 48/200\n8/8 [==============================] - 0s 8ms/step - loss: 25.9151 - val_loss: 48.1968\nEpoch 49/200\n8/8 [==============================] - 0s 8ms/step - loss: 25.9720 - val_loss: 50.1121\nEpoch 50/200\n8/8 [==============================] - 0s 8ms/step - loss: 25.4977 - val_loss: 48.7020\nEpoch 51/200\n8/8 [==============================] - 0s 8ms/step - loss: 25.7719 - val_loss: 50.3942\nEpoch 52/200\n8/8 [==============================] - 0s 8ms/step - loss: 25.3970 - val_loss: 48.9484\nEpoch 53/200\n8/8 [==============================] - 0s 8ms/step - loss: 25.4414 - val_loss: 48.8627\nEpoch 54/200\n8/8 [==============================] - 0s 8ms/step - loss: 25.0440 - val_loss: 49.7139\nEpoch 55/200\n8/8 [==============================] - 0s 8ms/step - loss: 25.1059 - val_loss: 49.0327\nEpoch 56/200\n8/8 [==============================] - 0s 8ms/step - loss: 24.8627 - val_loss: 49.6327\nEpoch 57/200\n8/8 [==============================] - 0s 8ms/step - loss: 25.0396 - val_loss: 49.9263\nEpoch 58/200\n8/8 [==============================] - 0s 8ms/step - loss: 25.0425 - val_loss: 49.3053\nEpoch 59/200\n8/8 [==============================] - 0s 9ms/step - loss: 24.6262 - val_loss: 50.7089\nEpoch 60/200\n8/8 [==============================] - 0s 11ms/step - loss: 24.6996 - val_loss: 49.2340\nEpoch 61/200\n8/8 [==============================] - 0s 8ms/step - loss: 24.2253 - val_loss: 50.1859\nEpoch 62/200\n8/8 [==============================] - 0s 8ms/step - loss: 24.4844 - val_loss: 49.7357\nEpoch 63/200\n8/8 [==============================] - 0s 8ms/step - loss: 24.3894 - val_loss: 49.2062\nEpoch 64/200\n8/8 [==============================] - 0s 8ms/step - loss: 24.0484 - val_loss: 50.3004\nEpoch 65/200\n8/8 [==============================] - 0s 8ms/step - loss: 24.5377 - val_loss: 48.9808\nEpoch 66/200\n8/8 [==============================] - 0s 8ms/step - loss: 24.1991 - val_loss: 49.9457\nEpoch 67/200\n8/8 [==============================] - 0s 8ms/step - loss: 23.7163 - val_loss: 50.0604\nEpoch 68/200\n8/8 [==============================] - 0s 9ms/step - loss: 23.7483 - val_loss: 49.5255\nEpoch 69/200\n8/8 [==============================] - 0s 8ms/step - loss: 23.4952 - val_loss: 49.7447\nEpoch 70/200\n8/8 [==============================] - 0s 8ms/step - loss: 23.3906 - val_loss: 50.0283\nEpoch 71/200\n8/8 [==============================] - 0s 8ms/step - loss: 23.3251 - val_loss: 49.6199\nEpoch 72/200\n8/8 [==============================] - 0s 8ms/step - loss: 23.5472 - val_loss: 50.1942\nEpoch 73/200\n8/8 [==============================] - 0s 8ms/step - loss: 23.4353 - val_loss: 50.0346\nEpoch 74/200\n8/8 [==============================] - 0s 8ms/step - loss: 23.5155 - val_loss: 51.2794\nEpoch 75/200\n8/8 [==============================] - 0s 8ms/step - loss: 23.7139 - val_loss: 49.4953\nEpoch 76/200\n8/8 [==============================] - 0s 8ms/step - loss: 23.6528 - val_loss: 50.7429\nEpoch 77/200\n8/8 [==============================] - 0s 8ms/step - loss: 23.3677 - val_loss: 49.6645\nEpoch 78/200\n8/8 [==============================] - 0s 8ms/step - loss: 23.2007 - val_loss: 49.6724\nEpoch 79/200\n8/8 [==============================] - 0s 8ms/step - loss: 22.9816 - val_loss: 50.6267\nEpoch 80/200\n8/8 [==============================] - 0s 8ms/step - loss: 22.6050 - val_loss: 50.2508\nEpoch 81/200\n8/8 [==============================] - 0s 8ms/step - loss: 22.5957 - val_loss: 50.4605\nEpoch 82/200\n8/8 [==============================] - 0s 8ms/step - loss: 22.5737 - val_loss: 49.9416\nEpoch 83/200\n8/8 [==============================] - 0s 8ms/step - loss: 22.4767 - val_loss: 49.7332\nEpoch 84/200\n8/8 [==============================] - 0s 8ms/step - loss: 22.3498 - val_loss: 50.9599\nEpoch 85/200\n8/8 [==============================] - 0s 8ms/step - loss: 22.6184 - val_loss: 49.7072\nEpoch 86/200\n8/8 [==============================] - 0s 8ms/step - loss: 23.5342 - val_loss: 50.3991\nEpoch 87/200\n8/8 [==============================] - 0s 8ms/step - loss: 22.5606 - val_loss: 50.9369\nEpoch 88/200\n8/8 [==============================] - 0s 8ms/step - loss: 23.1314 - val_loss: 49.3605\nEpoch 89/200\n8/8 [==============================] - 0s 8ms/step - loss: 22.7677 - val_loss: 51.6453\nEpoch 90/200\n8/8 [==============================] - 0s 8ms/step - loss: 22.1159 - val_loss: 50.0978\nEpoch 91/200\n8/8 [==============================] - 0s 8ms/step - loss: 21.7029 - val_loss: 50.0599\nEpoch 92/200\n8/8 [==============================] - 0s 8ms/step - loss: 22.2782 - val_loss: 50.8743\nEpoch 93/200\n8/8 [==============================] - 0s 8ms/step - loss: 21.7484 - val_loss: 49.8768\nEpoch 94/200\n8/8 [==============================] - 0s 8ms/step - loss: 21.4620 - val_loss: 50.6959\nEpoch 95/200\n8/8 [==============================] - 0s 8ms/step - loss: 21.6727 - val_loss: 49.4030\nEpoch 96/200\n8/8 [==============================] - 0s 8ms/step - loss: 21.3299 - val_loss: 51.5420\nEpoch 97/200\n8/8 [==============================] - 0s 8ms/step - loss: 21.7477 - val_loss: 50.3732\nEpoch 98/200\n8/8 [==============================] - 0s 8ms/step - loss: 21.2056 - val_loss: 50.1503\nEpoch 99/200\n8/8 [==============================] - 0s 8ms/step - loss: 20.9902 - val_loss: 50.8879\nEpoch 100/200\n8/8 [==============================] - 0s 8ms/step - loss: 21.0100 - val_loss: 51.0405\nEpoch 101/200\n8/8 [==============================] - 0s 8ms/step - loss: 21.0525 - val_loss: 50.6187\nEpoch 102/200\n8/8 [==============================] - 0s 8ms/step - loss: 21.0969 - val_loss: 50.5556\nEpoch 103/200\n8/8 [==============================] - 0s 8ms/step - loss: 20.9743 - val_loss: 50.3959\nEpoch 104/200\n8/8 [==============================] - 0s 8ms/step - loss: 20.8305 - val_loss: 51.3678\nEpoch 105/200\n8/8 [==============================] - 0s 8ms/step - loss: 20.9407 - val_loss: 50.6428\nEpoch 106/200\n8/8 [==============================] - 0s 8ms/step - loss: 21.4574 - val_loss: 50.1232\nEpoch 107/200\n8/8 [==============================] - 0s 8ms/step - loss: 21.1755 - val_loss: 51.0769\nEpoch 108/200\n8/8 [==============================] - 0s 8ms/step - loss: 20.7020 - val_loss: 50.6165\nEpoch 109/200\n8/8 [==============================] - 0s 9ms/step - loss: 20.4692 - val_loss: 51.4620\nEpoch 110/200\n8/8 [==============================] - 0s 8ms/step - loss: 20.2147 - val_loss: 50.4666\nEpoch 111/200\n8/8 [==============================] - 0s 9ms/step - loss: 20.1760 - val_loss: 50.8238\nEpoch 112/200\n8/8 [==============================] - 0s 9ms/step - loss: 20.3878 - val_loss: 50.9525\nEpoch 113/200\n8/8 [==============================] - 0s 8ms/step - loss: 20.3825 - val_loss: 51.0093\nEpoch 114/200\n8/8 [==============================] - 0s 8ms/step - loss: 20.0336 - val_loss: 50.0570\nEpoch 115/200\n8/8 [==============================] - 0s 8ms/step - loss: 20.1434 - val_loss: 50.7776\nEpoch 116/200\n8/8 [==============================] - 0s 8ms/step - loss: 19.6620 - val_loss: 50.3375\nEpoch 117/200\n8/8 [==============================] - 0s 8ms/step - loss: 19.6862 - val_loss: 51.6173\nEpoch 118/200\n8/8 [==============================] - 0s 8ms/step - loss: 19.4785 - val_loss: 51.2392\nEpoch 119/200\n8/8 [==============================] - 0s 8ms/step - loss: 19.5806 - val_loss: 51.3584\nEpoch 120/200\n8/8 [==============================] - 0s 8ms/step - loss: 19.5755 - val_loss: 50.5966\nEpoch 121/200\n8/8 [==============================] - 0s 8ms/step - loss: 19.6514 - val_loss: 52.0856\nEpoch 122/200\n8/8 [==============================] - 0s 8ms/step - loss: 19.7928 - val_loss: 50.9972\nEpoch 123/200\n8/8 [==============================] - 0s 8ms/step - loss: 19.1725 - val_loss: 51.1203\nEpoch 124/200\n8/8 [==============================] - 0s 8ms/step - loss: 18.9941 - val_loss: 51.1563\nEpoch 125/200\n8/8 [==============================] - 0s 8ms/step - loss: 19.1016 - val_loss: 51.0393\nEpoch 126/200\n8/8 [==============================] - 0s 8ms/step - loss: 18.7265 - val_loss: 50.9344\nEpoch 127/200\n8/8 [==============================] - 0s 8ms/step - loss: 18.8772 - val_loss: 51.2547\nEpoch 128/200\n8/8 [==============================] - 0s 8ms/step - loss: 18.7454 - val_loss: 50.9425\nEpoch 129/200\n8/8 [==============================] - 0s 8ms/step - loss: 18.6928 - val_loss: 51.2354\nEpoch 130/200\n8/8 [==============================] - 0s 8ms/step - loss: 18.8516 - val_loss: 51.0620\nEpoch 131/200\n8/8 [==============================] - 0s 8ms/step - loss: 19.1638 - val_loss: 52.5956\nEpoch 132/200\n8/8 [==============================] - 0s 8ms/step - loss: 19.2581 - val_loss: 50.5643\nEpoch 133/200\n8/8 [==============================] - 0s 8ms/step - loss: 18.9235 - val_loss: 51.6799\nEpoch 134/200\n8/8 [==============================] - 0s 8ms/step - loss: 18.2604 - val_loss: 51.1089\nEpoch 135/200\n8/8 [==============================] - 0s 8ms/step - loss: 18.7338 - val_loss: 51.6434\nEpoch 136/200\n8/8 [==============================] - 0s 8ms/step - loss: 19.6695 - val_loss: 52.7362\nEpoch 137/200\n8/8 [==============================] - 0s 8ms/step - loss: 19.6272 - val_loss: 49.9205\nEpoch 138/200\n8/8 [==============================] - 0s 8ms/step - loss: 20.5986 - val_loss: 53.5538\nEpoch 139/200\n8/8 [==============================] - 0s 8ms/step - loss: 19.7487 - val_loss: 50.2983\nEpoch 140/200\n8/8 [==============================] - 0s 8ms/step - loss: 18.1957 - val_loss: 51.1666\nEpoch 141/200\n8/8 [==============================] - 0s 8ms/step - loss: 17.8603 - val_loss: 51.2848\nEpoch 142/200\n8/8 [==============================] - 0s 8ms/step - loss: 17.7545 - val_loss: 51.4907\nEpoch 143/200\n8/8 [==============================] - 0s 8ms/step - loss: 17.7857 - val_loss: 51.3430\nEpoch 144/200\n8/8 [==============================] - 0s 8ms/step - loss: 17.4249 - val_loss: 51.5174\nEpoch 145/200\n8/8 [==============================] - 0s 8ms/step - loss: 17.5835 - val_loss: 52.0242\nEpoch 146/200\n8/8 [==============================] - 0s 8ms/step - loss: 17.3571 - val_loss: 51.0991\nEpoch 147/200\n8/8 [==============================] - 0s 8ms/step - loss: 17.5214 - val_loss: 50.4668\nEpoch 148/200\n8/8 [==============================] - 0s 8ms/step - loss: 18.1261 - val_loss: 51.4138\nEpoch 149/200\n8/8 [==============================] - 0s 8ms/step - loss: 17.6294 - val_loss: 52.6961\nEpoch 150/200\n8/8 [==============================] - 0s 8ms/step - loss: 17.9160 - val_loss: 52.2974\nEpoch 151/200\n8/8 [==============================] - 0s 8ms/step - loss: 17.4318 - val_loss: 51.5883\nEpoch 152/200\n8/8 [==============================] - 0s 8ms/step - loss: 17.3715 - val_loss: 51.7278\nEpoch 153/200\n8/8 [==============================] - 0s 8ms/step - loss: 17.0175 - val_loss: 51.9149\nEpoch 154/200\n8/8 [==============================] - 0s 8ms/step - loss: 17.0007 - val_loss: 51.3155\nEpoch 155/200\n8/8 [==============================] - 0s 8ms/step - loss: 16.7354 - val_loss: 51.8666\nEpoch 156/200\n8/8 [==============================] - 0s 8ms/step - loss: 16.5473 - val_loss: 51.5215\nEpoch 157/200\n8/8 [==============================] - 0s 8ms/step - loss: 16.7879 - val_loss: 50.8675\nEpoch 158/200\n8/8 [==============================] - 0s 8ms/step - loss: 16.5899 - val_loss: 50.9985\nEpoch 159/200\n8/8 [==============================] - 0s 8ms/step - loss: 17.0166 - val_loss: 52.8479\nEpoch 160/200\n8/8 [==============================] - 0s 9ms/step - loss: 17.4589 - val_loss: 52.4768\nEpoch 161/200\n8/8 [==============================] - 0s 9ms/step - loss: 17.5399 - val_loss: 50.2587\nEpoch 162/200\n8/8 [==============================] - 0s 8ms/step - loss: 17.1359 - val_loss: 51.5243\nEpoch 163/200\n8/8 [==============================] - 0s 8ms/step - loss: 16.2770 - val_loss: 52.5983\nEpoch 164/200\n8/8 [==============================] - 0s 8ms/step - loss: 16.5505 - val_loss: 51.7276\nEpoch 165/200\n8/8 [==============================] - 0s 9ms/step - loss: 16.3618 - val_loss: 51.9345\nEpoch 166/200\n8/8 [==============================] - 0s 8ms/step - loss: 16.3841 - val_loss: 52.2174\nEpoch 167/200\n8/8 [==============================] - 0s 8ms/step - loss: 16.6574 - val_loss: 51.6323\nEpoch 168/200\n8/8 [==============================] - 0s 8ms/step - loss: 16.7193 - val_loss: 51.2813\nEpoch 169/200\n8/8 [==============================] - 0s 8ms/step - loss: 16.3304 - val_loss: 52.7014\nEpoch 170/200\n8/8 [==============================] - 0s 8ms/step - loss: 16.2398 - val_loss: 51.3211\nEpoch 171/200\n8/8 [==============================] - 0s 8ms/step - loss: 16.1404 - val_loss: 52.3500\nEpoch 172/200\n8/8 [==============================] - 0s 8ms/step - loss: 16.8021 - val_loss: 51.6433\nEpoch 173/200\n8/8 [==============================] - 0s 8ms/step - loss: 15.8341 - val_loss: 50.9635\nEpoch 174/200\n8/8 [==============================] - 0s 8ms/step - loss: 16.2150 - val_loss: 52.5055\nEpoch 175/200\n8/8 [==============================] - 0s 8ms/step - loss: 15.6272 - val_loss: 51.0669\nEpoch 176/200\n8/8 [==============================] - 0s 8ms/step - loss: 16.4019 - val_loss: 51.9000\nEpoch 177/200\n8/8 [==============================] - 0s 8ms/step - loss: 15.7654 - val_loss: 51.7224\nEpoch 178/200\n8/8 [==============================] - 0s 8ms/step - loss: 15.2956 - val_loss: 52.1887\nEpoch 179/200\n8/8 [==============================] - 0s 8ms/step - loss: 15.5346 - val_loss: 53.0749\nEpoch 180/200\n8/8 [==============================] - 0s 8ms/step - loss: 15.6251 - val_loss: 51.1124\nEpoch 181/200\n8/8 [==============================] - 0s 8ms/step - loss: 16.1110 - val_loss: 52.8597\nEpoch 182/200\n8/8 [==============================] - 0s 8ms/step - loss: 16.0031 - val_loss: 53.2857\nEpoch 183/200\n8/8 [==============================] - 0s 8ms/step - loss: 16.4036 - val_loss: 50.3643\nEpoch 184/200\n8/8 [==============================] - 0s 8ms/step - loss: 15.8361 - val_loss: 52.2752\nEpoch 185/200\n8/8 [==============================] - 0s 8ms/step - loss: 15.2535 - val_loss: 52.4489\nEpoch 186/200\n8/8 [==============================] - 0s 8ms/step - loss: 15.4420 - val_loss: 51.3902\nEpoch 187/200\n8/8 [==============================] - 0s 8ms/step - loss: 15.1292 - val_loss: 50.8872\nEpoch 188/200\n8/8 [==============================] - 0s 8ms/step - loss: 15.2146 - val_loss: 52.7379\nEpoch 189/200\n8/8 [==============================] - 0s 8ms/step - loss: 14.9485 - val_loss: 51.9663\nEpoch 190/200\n8/8 [==============================] - 0s 8ms/step - loss: 15.1141 - val_loss: 51.1863\nEpoch 191/200\n8/8 [==============================] - 0s 8ms/step - loss: 15.0056 - val_loss: 51.5475\nEpoch 192/200\n8/8 [==============================] - 0s 8ms/step - loss: 15.2243 - val_loss: 51.7480\nEpoch 193/200\n8/8 [==============================] - 0s 8ms/step - loss: 14.9745 - val_loss: 51.0408\nEpoch 194/200\n8/8 [==============================] - 0s 8ms/step - loss: 15.1838 - val_loss: 50.9699\nEpoch 195/200\n8/8 [==============================] - 0s 8ms/step - loss: 14.5625 - val_loss: 52.6726\nEpoch 196/200\n8/8 [==============================] - 0s 8ms/step - loss: 15.0560 - val_loss: 52.0253\nEpoch 197/200\n8/8 [==============================] - 0s 8ms/step - loss: 14.5217 - val_loss: 51.5442\nEpoch 198/200\n8/8 [==============================] - 0s 8ms/step - loss: 15.2202 - val_loss: 51.6457\nEpoch 199/200\n8/8 [==============================] - 0s 8ms/step - loss: 14.6386 - val_loss: 52.2278\nEpoch 200/200\n8/8 [==============================] - 0s 8ms/step - loss: 14.3658 - val_loss: 52.2378\n","output_type":"stream"},{"execution_count":213,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7c4300426b00>"},"metadata":{}}]},{"cell_type":"code","source":"model2.fit(X_train,y_train,epochs=200,validation_split=0.3)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T11:19:09.546845Z","iopub.execute_input":"2023-12-03T11:19:09.547727Z","iopub.status.idle":"2023-12-03T11:19:21.182370Z","shell.execute_reply.started":"2023-12-03T11:19:09.547695Z","shell.execute_reply":"2023-12-03T11:19:21.181393Z"},"trusted":true},"execution_count":214,"outputs":[{"name":"stdout","text":"Epoch 1/200\n8/8 [==============================] - 0s 12ms/step - loss: 12.3905 - val_loss: 54.6211\nEpoch 2/200\n8/8 [==============================] - 0s 7ms/step - loss: 12.3370 - val_loss: 55.9137\nEpoch 3/200\n8/8 [==============================] - 0s 7ms/step - loss: 11.2096 - val_loss: 55.8634\nEpoch 4/200\n8/8 [==============================] - 0s 7ms/step - loss: 11.1119 - val_loss: 56.4323\nEpoch 5/200\n8/8 [==============================] - 0s 7ms/step - loss: 11.5393 - val_loss: 56.1552\nEpoch 6/200\n8/8 [==============================] - 0s 8ms/step - loss: 11.4048 - val_loss: 55.9647\nEpoch 7/200\n8/8 [==============================] - 0s 9ms/step - loss: 12.6079 - val_loss: 56.2876\nEpoch 8/200\n8/8 [==============================] - 0s 7ms/step - loss: 11.0317 - val_loss: 56.1927\nEpoch 9/200\n8/8 [==============================] - 0s 7ms/step - loss: 11.9142 - val_loss: 55.4992\nEpoch 10/200\n8/8 [==============================] - 0s 7ms/step - loss: 12.5017 - val_loss: 56.3688\nEpoch 11/200\n8/8 [==============================] - 0s 7ms/step - loss: 11.8435 - val_loss: 56.5216\nEpoch 12/200\n8/8 [==============================] - 0s 7ms/step - loss: 11.5713 - val_loss: 55.8151\nEpoch 13/200\n8/8 [==============================] - 0s 7ms/step - loss: 11.8713 - val_loss: 55.9140\nEpoch 14/200\n8/8 [==============================] - 0s 7ms/step - loss: 11.9216 - val_loss: 55.3918\nEpoch 15/200\n8/8 [==============================] - 0s 7ms/step - loss: 11.9359 - val_loss: 56.1059\nEpoch 16/200\n8/8 [==============================] - 0s 7ms/step - loss: 11.2430 - val_loss: 55.9644\nEpoch 17/200\n8/8 [==============================] - 0s 7ms/step - loss: 12.1562 - val_loss: 57.5336\nEpoch 18/200\n8/8 [==============================] - 0s 7ms/step - loss: 12.2080 - val_loss: 57.5266\nEpoch 19/200\n8/8 [==============================] - 0s 7ms/step - loss: 11.7528 - val_loss: 57.6624\nEpoch 20/200\n8/8 [==============================] - 0s 7ms/step - loss: 10.9001 - val_loss: 57.7211\nEpoch 21/200\n8/8 [==============================] - 0s 7ms/step - loss: 10.9367 - val_loss: 57.6655\nEpoch 22/200\n8/8 [==============================] - 0s 7ms/step - loss: 12.2997 - val_loss: 57.7795\nEpoch 23/200\n8/8 [==============================] - 0s 7ms/step - loss: 13.0171 - val_loss: 56.1970\nEpoch 24/200\n8/8 [==============================] - 0s 7ms/step - loss: 11.3119 - val_loss: 55.8279\nEpoch 25/200\n8/8 [==============================] - 0s 7ms/step - loss: 9.8620 - val_loss: 57.7508\nEpoch 26/200\n8/8 [==============================] - 0s 7ms/step - loss: 10.2044 - val_loss: 56.7288\nEpoch 27/200\n8/8 [==============================] - 0s 7ms/step - loss: 10.1658 - val_loss: 58.2908\nEpoch 28/200\n8/8 [==============================] - 0s 7ms/step - loss: 11.1369 - val_loss: 57.6677\nEpoch 29/200\n8/8 [==============================] - 0s 7ms/step - loss: 10.1425 - val_loss: 58.0886\nEpoch 30/200\n8/8 [==============================] - 0s 7ms/step - loss: 11.0507 - val_loss: 56.9028\nEpoch 31/200\n8/8 [==============================] - 0s 7ms/step - loss: 10.7188 - val_loss: 57.3054\nEpoch 32/200\n8/8 [==============================] - 0s 7ms/step - loss: 10.6999 - val_loss: 57.7088\nEpoch 33/200\n8/8 [==============================] - 0s 7ms/step - loss: 10.5368 - val_loss: 57.9202\nEpoch 34/200\n8/8 [==============================] - 0s 7ms/step - loss: 10.1848 - val_loss: 56.8433\nEpoch 35/200\n8/8 [==============================] - 0s 7ms/step - loss: 9.5102 - val_loss: 57.3249\nEpoch 36/200\n8/8 [==============================] - 0s 7ms/step - loss: 9.0217 - val_loss: 57.4638\nEpoch 37/200\n8/8 [==============================] - 0s 7ms/step - loss: 10.4323 - val_loss: 57.1259\nEpoch 38/200\n8/8 [==============================] - 0s 7ms/step - loss: 9.1497 - val_loss: 58.6365\nEpoch 39/200\n8/8 [==============================] - 0s 7ms/step - loss: 9.6168 - val_loss: 56.9010\nEpoch 40/200\n8/8 [==============================] - 0s 7ms/step - loss: 9.0974 - val_loss: 57.8682\nEpoch 41/200\n8/8 [==============================] - 0s 7ms/step - loss: 9.5512 - val_loss: 56.4139\nEpoch 42/200\n8/8 [==============================] - 0s 7ms/step - loss: 10.3166 - val_loss: 59.2035\nEpoch 43/200\n8/8 [==============================] - 0s 7ms/step - loss: 10.5809 - val_loss: 57.3997\nEpoch 44/200\n8/8 [==============================] - 0s 7ms/step - loss: 10.1753 - val_loss: 60.3282\nEpoch 45/200\n8/8 [==============================] - 0s 7ms/step - loss: 11.9170 - val_loss: 57.0313\nEpoch 46/200\n8/8 [==============================] - 0s 7ms/step - loss: 9.9399 - val_loss: 57.8113\nEpoch 47/200\n8/8 [==============================] - 0s 7ms/step - loss: 9.5837 - val_loss: 58.4889\nEpoch 48/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.4151 - val_loss: 57.9010\nEpoch 49/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.9750 - val_loss: 56.2339\nEpoch 50/200\n8/8 [==============================] - 0s 7ms/step - loss: 9.5642 - val_loss: 57.9387\nEpoch 51/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.2768 - val_loss: 57.8586\nEpoch 52/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.0639 - val_loss: 58.5785\nEpoch 53/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.9874 - val_loss: 59.4705\nEpoch 54/200\n8/8 [==============================] - 0s 7ms/step - loss: 9.2143 - val_loss: 57.2949\nEpoch 55/200\n8/8 [==============================] - 0s 7ms/step - loss: 9.3935 - val_loss: 57.9975\nEpoch 56/200\n8/8 [==============================] - 0s 7ms/step - loss: 9.3921 - val_loss: 58.6252\nEpoch 57/200\n8/8 [==============================] - 0s 7ms/step - loss: 9.6225 - val_loss: 58.8939\nEpoch 58/200\n8/8 [==============================] - 0s 7ms/step - loss: 10.5903 - val_loss: 58.6036\nEpoch 59/200\n8/8 [==============================] - 0s 7ms/step - loss: 10.8532 - val_loss: 58.2927\nEpoch 60/200\n8/8 [==============================] - 0s 7ms/step - loss: 9.3263 - val_loss: 57.1626\nEpoch 61/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.8383 - val_loss: 58.8167\nEpoch 62/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.7556 - val_loss: 57.3648\nEpoch 63/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.1577 - val_loss: 58.3114\nEpoch 64/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.7687 - val_loss: 57.9081\nEpoch 65/200\n8/8 [==============================] - 0s 7ms/step - loss: 9.4863 - val_loss: 59.1849\nEpoch 66/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.6773 - val_loss: 58.7542\nEpoch 67/200\n8/8 [==============================] - 0s 7ms/step - loss: 9.1818 - val_loss: 58.8154\nEpoch 68/200\n8/8 [==============================] - 0s 7ms/step - loss: 9.3402 - val_loss: 59.2289\nEpoch 69/200\n8/8 [==============================] - 0s 7ms/step - loss: 9.1112 - val_loss: 58.4550\nEpoch 70/200\n8/8 [==============================] - 0s 7ms/step - loss: 7.9222 - val_loss: 58.4019\nEpoch 71/200\n8/8 [==============================] - 0s 7ms/step - loss: 7.5156 - val_loss: 58.0011\nEpoch 72/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.2871 - val_loss: 57.5737\nEpoch 73/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.1995 - val_loss: 58.1529\nEpoch 74/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.2673 - val_loss: 56.9549\nEpoch 75/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.8962 - val_loss: 57.6815\nEpoch 76/200\n8/8 [==============================] - 0s 7ms/step - loss: 7.6671 - val_loss: 58.4907\nEpoch 77/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.3436 - val_loss: 57.9473\nEpoch 78/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.5242 - val_loss: 59.4424\nEpoch 79/200\n8/8 [==============================] - 0s 7ms/step - loss: 9.2682 - val_loss: 58.0401\nEpoch 80/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.7836 - val_loss: 58.8334\nEpoch 81/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.7251 - val_loss: 58.0289\nEpoch 82/200\n8/8 [==============================] - 0s 7ms/step - loss: 7.5355 - val_loss: 59.1725\nEpoch 83/200\n8/8 [==============================] - 0s 7ms/step - loss: 7.8190 - val_loss: 58.9934\nEpoch 84/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.9591 - val_loss: 58.8607\nEpoch 85/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.9660 - val_loss: 59.3839\nEpoch 86/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.6917 - val_loss: 59.5051\nEpoch 87/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.8048 - val_loss: 62.1448\nEpoch 88/200\n8/8 [==============================] - 0s 7ms/step - loss: 11.5533 - val_loss: 58.8112\nEpoch 89/200\n8/8 [==============================] - 0s 7ms/step - loss: 9.1597 - val_loss: 59.8563\nEpoch 90/200\n8/8 [==============================] - 0s 7ms/step - loss: 7.9218 - val_loss: 58.1732\nEpoch 91/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.6854 - val_loss: 59.4860\nEpoch 92/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.0432 - val_loss: 58.9403\nEpoch 93/200\n8/8 [==============================] - 0s 7ms/step - loss: 7.1826 - val_loss: 58.7717\nEpoch 94/200\n8/8 [==============================] - 0s 7ms/step - loss: 7.2362 - val_loss: 58.9870\nEpoch 95/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.3965 - val_loss: 58.6984\nEpoch 96/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.3789 - val_loss: 59.0163\nEpoch 97/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.3031 - val_loss: 59.7904\nEpoch 98/200\n8/8 [==============================] - 0s 7ms/step - loss: 7.6051 - val_loss: 59.0287\nEpoch 99/200\n8/8 [==============================] - 0s 7ms/step - loss: 7.0214 - val_loss: 58.9111\nEpoch 100/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.9874 - val_loss: 59.2023\nEpoch 101/200\n8/8 [==============================] - 0s 7ms/step - loss: 7.3922 - val_loss: 58.9122\nEpoch 102/200\n8/8 [==============================] - 0s 7ms/step - loss: 7.5788 - val_loss: 58.3261\nEpoch 103/200\n8/8 [==============================] - 0s 7ms/step - loss: 7.3283 - val_loss: 59.7405\nEpoch 104/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.8585 - val_loss: 58.4949\nEpoch 105/200\n8/8 [==============================] - 0s 7ms/step - loss: 7.1893 - val_loss: 59.0454\nEpoch 106/200\n8/8 [==============================] - 0s 7ms/step - loss: 7.3786 - val_loss: 57.9924\nEpoch 107/200\n8/8 [==============================] - 0s 7ms/step - loss: 7.6464 - val_loss: 58.5223\nEpoch 108/200\n8/8 [==============================] - 0s 8ms/step - loss: 8.3042 - val_loss: 59.0016\nEpoch 109/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.0364 - val_loss: 59.6817\nEpoch 110/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.6910 - val_loss: 60.3346\nEpoch 111/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.0760 - val_loss: 59.5407\nEpoch 112/200\n8/8 [==============================] - 0s 7ms/step - loss: 9.3808 - val_loss: 59.1699\nEpoch 113/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.2538 - val_loss: 58.4552\nEpoch 114/200\n8/8 [==============================] - 0s 7ms/step - loss: 7.0799 - val_loss: 59.6226\nEpoch 115/200\n8/8 [==============================] - 0s 7ms/step - loss: 7.2786 - val_loss: 59.3321\nEpoch 116/200\n8/8 [==============================] - 0s 7ms/step - loss: 7.4665 - val_loss: 59.1121\nEpoch 117/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.6593 - val_loss: 58.9315\nEpoch 118/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.3971 - val_loss: 59.5689\nEpoch 119/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.1735 - val_loss: 59.8282\nEpoch 120/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.9755 - val_loss: 58.8482\nEpoch 121/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.7808 - val_loss: 58.8067\nEpoch 122/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.2753 - val_loss: 61.0425\nEpoch 123/200\n8/8 [==============================] - 0s 7ms/step - loss: 7.7521 - val_loss: 60.5013\nEpoch 124/200\n8/8 [==============================] - 0s 7ms/step - loss: 8.8241 - val_loss: 60.0404\nEpoch 125/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.8182 - val_loss: 59.1463\nEpoch 126/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.5878 - val_loss: 59.0784\nEpoch 127/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.9628 - val_loss: 59.4948\nEpoch 128/200\n8/8 [==============================] - 0s 7ms/step - loss: 5.8369 - val_loss: 59.5460\nEpoch 129/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.5232 - val_loss: 59.8208\nEpoch 130/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.0229 - val_loss: 58.4700\nEpoch 131/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.5500 - val_loss: 59.7671\nEpoch 132/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.2392 - val_loss: 59.0883\nEpoch 133/200\n8/8 [==============================] - 0s 7ms/step - loss: 5.4247 - val_loss: 59.5104\nEpoch 134/200\n8/8 [==============================] - 0s 7ms/step - loss: 5.6880 - val_loss: 59.3908\nEpoch 135/200\n8/8 [==============================] - 0s 7ms/step - loss: 5.5938 - val_loss: 59.0376\nEpoch 136/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.1941 - val_loss: 58.7776\nEpoch 137/200\n8/8 [==============================] - 0s 8ms/step - loss: 5.8059 - val_loss: 59.7535\nEpoch 138/200\n8/8 [==============================] - 0s 10ms/step - loss: 5.7582 - val_loss: 59.3698\nEpoch 139/200\n8/8 [==============================] - 0s 7ms/step - loss: 5.8063 - val_loss: 59.4636\nEpoch 140/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.0139 - val_loss: 60.0225\nEpoch 141/200\n8/8 [==============================] - 0s 7ms/step - loss: 5.2333 - val_loss: 59.6474\nEpoch 142/200\n8/8 [==============================] - 0s 7ms/step - loss: 5.3170 - val_loss: 60.2412\nEpoch 143/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.1764 - val_loss: 59.5690\nEpoch 144/200\n8/8 [==============================] - 0s 7ms/step - loss: 5.8472 - val_loss: 59.9487\nEpoch 145/200\n8/8 [==============================] - 0s 7ms/step - loss: 5.1859 - val_loss: 60.1623\nEpoch 146/200\n8/8 [==============================] - 0s 7ms/step - loss: 4.9960 - val_loss: 58.5730\nEpoch 147/200\n8/8 [==============================] - 0s 7ms/step - loss: 5.3093 - val_loss: 59.7870\nEpoch 148/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.0590 - val_loss: 60.0482\nEpoch 149/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.0424 - val_loss: 60.3823\nEpoch 150/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.5837 - val_loss: 60.8971\nEpoch 151/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.8208 - val_loss: 59.1527\nEpoch 152/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.2739 - val_loss: 59.5184\nEpoch 153/200\n8/8 [==============================] - 0s 7ms/step - loss: 5.9607 - val_loss: 60.2057\nEpoch 154/200\n8/8 [==============================] - 0s 7ms/step - loss: 5.9606 - val_loss: 60.8757\nEpoch 155/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.9350 - val_loss: 60.8618\nEpoch 156/200\n8/8 [==============================] - 0s 7ms/step - loss: 7.4489 - val_loss: 58.6297\nEpoch 157/200\n8/8 [==============================] - 0s 8ms/step - loss: 7.9460 - val_loss: 60.3291\nEpoch 158/200\n8/8 [==============================] - 0s 8ms/step - loss: 9.1437 - val_loss: 59.7764\nEpoch 159/200\n8/8 [==============================] - 0s 8ms/step - loss: 6.6787 - val_loss: 60.0965\nEpoch 160/200\n8/8 [==============================] - 0s 8ms/step - loss: 6.3950 - val_loss: 59.3820\nEpoch 161/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.7063 - val_loss: 59.6152\nEpoch 162/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.4602 - val_loss: 59.8277\nEpoch 163/200\n8/8 [==============================] - 0s 7ms/step - loss: 5.2872 - val_loss: 61.9048\nEpoch 164/200\n8/8 [==============================] - 0s 8ms/step - loss: 5.9869 - val_loss: 60.8785\nEpoch 165/200\n8/8 [==============================] - 0s 8ms/step - loss: 6.0692 - val_loss: 59.6696\nEpoch 166/200\n8/8 [==============================] - 0s 7ms/step - loss: 5.6423 - val_loss: 60.2992\nEpoch 167/200\n8/8 [==============================] - 0s 7ms/step - loss: 5.6747 - val_loss: 60.0361\nEpoch 168/200\n8/8 [==============================] - 0s 7ms/step - loss: 5.3192 - val_loss: 60.9088\nEpoch 169/200\n8/8 [==============================] - 0s 7ms/step - loss: 5.4418 - val_loss: 60.5918\nEpoch 170/200\n8/8 [==============================] - 0s 8ms/step - loss: 5.5351 - val_loss: 59.2318\nEpoch 171/200\n8/8 [==============================] - 0s 8ms/step - loss: 6.0223 - val_loss: 60.6447\nEpoch 172/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.6650 - val_loss: 60.7167\nEpoch 173/200\n8/8 [==============================] - 0s 8ms/step - loss: 7.0668 - val_loss: 60.8697\nEpoch 174/200\n8/8 [==============================] - 0s 7ms/step - loss: 6.6930 - val_loss: 60.4679\nEpoch 175/200\n8/8 [==============================] - 0s 7ms/step - loss: 5.7691 - val_loss: 59.2554\nEpoch 176/200\n8/8 [==============================] - 0s 7ms/step - loss: 5.9564 - val_loss: 59.4528\nEpoch 177/200\n8/8 [==============================] - 0s 7ms/step - loss: 5.5020 - val_loss: 60.1189\nEpoch 178/200\n8/8 [==============================] - 0s 7ms/step - loss: 5.9051 - val_loss: 60.0576\nEpoch 179/200\n8/8 [==============================] - 0s 7ms/step - loss: 5.2953 - val_loss: 60.4230\nEpoch 180/200\n8/8 [==============================] - 0s 7ms/step - loss: 5.3934 - val_loss: 60.5832\nEpoch 181/200\n8/8 [==============================] - 0s 7ms/step - loss: 4.6630 - val_loss: 59.9913\nEpoch 182/200\n8/8 [==============================] - 0s 7ms/step - loss: 5.0480 - val_loss: 60.9656\nEpoch 183/200\n8/8 [==============================] - 0s 8ms/step - loss: 5.2440 - val_loss: 60.5212\nEpoch 184/200\n8/8 [==============================] - 0s 7ms/step - loss: 5.0015 - val_loss: 60.6163\nEpoch 185/200\n8/8 [==============================] - 0s 8ms/step - loss: 6.3931 - val_loss: 61.0821\nEpoch 186/200\n8/8 [==============================] - 0s 9ms/step - loss: 4.9031 - val_loss: 61.1264\nEpoch 187/200\n8/8 [==============================] - 0s 9ms/step - loss: 5.2970 - val_loss: 60.7826\nEpoch 188/200\n8/8 [==============================] - 0s 9ms/step - loss: 5.4579 - val_loss: 60.1816\nEpoch 189/200\n8/8 [==============================] - 0s 8ms/step - loss: 5.7309 - val_loss: 60.8121\nEpoch 190/200\n8/8 [==============================] - 0s 9ms/step - loss: 5.6014 - val_loss: 60.2173\nEpoch 191/200\n8/8 [==============================] - 0s 8ms/step - loss: 5.8353 - val_loss: 61.0095\nEpoch 192/200\n8/8 [==============================] - 0s 9ms/step - loss: 6.1936 - val_loss: 60.3689\nEpoch 193/200\n8/8 [==============================] - 0s 10ms/step - loss: 7.1063 - val_loss: 61.2150\nEpoch 194/200\n8/8 [==============================] - 0s 8ms/step - loss: 5.2974 - val_loss: 60.6678\nEpoch 195/200\n8/8 [==============================] - 0s 8ms/step - loss: 4.5525 - val_loss: 60.9870\nEpoch 196/200\n8/8 [==============================] - 0s 8ms/step - loss: 4.3722 - val_loss: 61.2024\nEpoch 197/200\n8/8 [==============================] - 0s 8ms/step - loss: 4.8077 - val_loss: 60.0583\nEpoch 198/200\n8/8 [==============================] - 0s 8ms/step - loss: 4.6373 - val_loss: 60.0041\nEpoch 199/200\n8/8 [==============================] - 0s 7ms/step - loss: 4.7640 - val_loss: 60.3817\nEpoch 200/200\n8/8 [==============================] - 0s 9ms/step - loss: 5.2186 - val_loss: 60.3083\n","output_type":"stream"},{"execution_count":214,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7c4308213b50>"},"metadata":{}}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-03T11:18:39.552007Z","iopub.execute_input":"2023-12-03T11:18:39.552363Z","iopub.status.idle":"2023-12-03T11:18:39.584526Z","shell.execute_reply.started":"2023-12-03T11:18:39.552333Z","shell.execute_reply":"2023-12-03T11:18:39.583502Z"},"trusted":true},"execution_count":211,"outputs":[{"name":"stdout","text":"Model: \"model_34\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_33 (InputLayer)       [(None, 10)]                 0         []                            \n                                                                                                  \n dense_168 (Dense)           (None, 124)                  1364      ['input_33[0][0]']            \n                                                                                                  \n dense_169 (Dense)           (None, 128)                  16000     ['dense_168[0][0]']           \n                                                                                                  \n super_dense_15 (SuperDense  (None, 4096)                 20097     ['dense_168[0][0]']           \n )                                                                                                \n                                                                                                  \n concatenate_32 (Concatenat  (None, 4224)                 0         ['dense_169[0][0]',           \n e)                                                                  'super_dense_15[0][0]']      \n                                                                                                  \n dense_171 (Dense)           (None, 12)                   50700     ['concatenate_32[0][0]']      \n                                                                                                  \n dense_172 (Dense)           (None, 1)                    13        ['dense_171[0][0]']           \n                                                                                                  \n==================================================================================================\nTotal params: 88174 (344.43 KB)\nTrainable params: 88174 (344.43 KB)\nNon-trainable params: 0 (0.00 Byte)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model2.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-03T11:18:39.585974Z","iopub.execute_input":"2023-12-03T11:18:39.586436Z","iopub.status.idle":"2023-12-03T11:18:39.614745Z","shell.execute_reply.started":"2023-12-03T11:18:39.586404Z","shell.execute_reply":"2023-12-03T11:18:39.613743Z"},"trusted":true},"execution_count":212,"outputs":[{"name":"stdout","text":"Model: \"model_35\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_34 (InputLayer)       [(None, 10)]                 0         []                            \n                                                                                                  \n dense_173 (Dense)           (None, 124)                  1364      ['input_34[0][0]']            \n                                                                                                  \n dense_174 (Dense)           (None, 128)                  16000     ['dense_173[0][0]']           \n                                                                                                  \n dense_175 (Dense)           (None, 128)                  16000     ['dense_173[0][0]']           \n                                                                                                  \n concatenate_33 (Concatenat  (None, 256)                  0         ['dense_174[0][0]',           \n e)                                                                  'dense_175[0][0]']           \n                                                                                                  \n dense_176 (Dense)           (None, 256)                  65792     ['concatenate_33[0][0]']      \n                                                                                                  \n dense_177 (Dense)           (None, 1)                    257       ['dense_176[0][0]']           \n                                                                                                  \n==================================================================================================\nTotal params: 99413 (388.33 KB)\nTrainable params: 99413 (388.33 KB)\nNon-trainable params: 0 (0.00 Byte)\n__________________________________________________________________________________________________\n","output_type":"stream"}]}]}